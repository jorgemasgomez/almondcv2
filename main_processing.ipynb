{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch images processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from calibrations import  build_calibration, calibrate_color_and_distortion, calibrate_color\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from aux_functions import slicing, obtain_pixel_metric, divide_in_sets, ungroup_pic, prepare_pose_dataset\n",
    "from model_class import model_segmentation\n",
    "from pictures_class import pictures\n",
    "from morphometrics_functions import install_morphometrics_packages_r, exploratory_morphometrics_r, run_efourier_pca_morphometrics_r, run_plot_pca_morphometrics_r, run_kmeans_efourier_r, run_obtain_kmeans_classification_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "raw_folder=\"C:/Users/Pheno/Documents/database_almondcv2/2023/all_sessions_2023/errores\"\n",
    "chessboards=\"C:/Users/Pheno/Documents/database_almondcv2/calibracion/chessboards\"\n",
    "mtx_input_path=os.path.join(chessboards,\"calibration_mtx.npz\") ## for distorsion\n",
    "standard_matrix_color=\"C:/Users/Pheno/Documents/database_almondcv2/2023/all_sessions_2023/RGB_SEED_0509_2024-09-05-12-29-37_2.jpg\" ### a picture to select if some pictures produces errors in color \n",
    "info_data_2022=\"C:/Users/Pheno/Documents/database_almondcv2/info_data.txt\"\n",
    "info_data_2023=\"C:/Users/Pheno/Documents/database_almondcv2/info_data_2023.txt\"\n",
    "\n",
    "zip_file_coin=os.path.join(working_directory,\"coin_640_slices_2023set.zip\")\n",
    "zip_file_group=os.path.join(working_directory,\"rectangles_set_2023_shell.zip\")\n",
    "zip_file_shell=os.path.join(working_directory,\"shell_2022_320.zip\")\n",
    "zip_file_seed=os.path.join(working_directory,\"seed_2022_21102024.zip\")\n",
    "\n",
    "\n",
    "models_directory=\"C:/Users/Pheno/Documents/database_almondcv2/models/\"\n",
    "pre_model=os.path.join(models_directory, \"yolo11s-seg.pt\")\n",
    "\n",
    "coin_model_path=os.path.join(models_directory,\"coin_2023_yolov11s_640.pt\")\n",
    "\n",
    "group_model_path_1=os.path.join(models_directory, \"rectangles_shell_2023_imgsize_1280.pt\")\n",
    "group_model_path_2=os.path.join(models_directory, \"rectangles_seed_2023_imgsz_1600.pt\")\n",
    "group_model_path_2022=\"rectangle_2022_yolov11s_1280.pt\"\n",
    "\n",
    "shell_model_path=os.path.join(models_directory, \"shell_2022_yolov11s_320.pt\")\n",
    "seed_model_path=os.path.join(models_directory, \"seed_2022_yolov11s_320.pt\")\n",
    "#outputs\n",
    "output=\"C:/Users/Pheno/Documents/database_almondcv2\"\n",
    "output_calibrated=os.path.join(output,\"calibrated_pics_2022/\")\n",
    "os.makedirs(output_calibrated, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color and distorsion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to create distortion model\n",
    "build_calibration(chessboardSize=(6, 8), frameSize=(5472,3648), dir_path=chessboards, \n",
    "                  image_format=\".jpg\", size_of_chessboard_squares_mm=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora mismo esta puesto en modo calibracion los errores utilizando una foto como referencia, para calibracion normal quitar la standard_matrix_color\n",
    "calibrate_color_and_distortion(raw_folder=raw_folder,mtx_input_path=mtx_input_path,output_calibrated=output_calibrated,\n",
    "                                radius_param=10, standard_matrix=standard_matrix_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si solo quieres hacer color esta la función\n",
    "\n",
    "# calibrate_color(input_folder=raw_folder, output_path=output_calibrated,standard_matrix=standard_matrix_color)\n",
    "calibrate_color(input_folder=raw_folder, output_path=output_calibrated,standard_matrix=standard_matrix_color,\n",
    "                 force_standard_matrix=\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHUNK para mover automaticamente lo que este en la lista errores a donde tu queiras\n",
    "#first we move \n",
    "\n",
    "carpeta_destino = os.path.join(raw_folder,\"errores\")    # Cambia esto por la ruta correcta\n",
    "\n",
    "# Crea la carpeta de destino si no existe\n",
    "os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "\n",
    "# Lee el archivo de texto con los nombres de las imágenes\n",
    "with open(os.path.join(output_calibrated,\"errors_in_calibrations.txt\"), \"r\") as archivo:\n",
    "    for nombre_imagen in archivo:\n",
    "        nombre_imagen = nombre_imagen.strip()  # Elimina espacios en blanco y saltos de línea\n",
    "        ruta_imagen_origen = os.path.join(raw_folder, nombre_imagen)\n",
    "        \n",
    "        # Verifica si el archivo existe antes de moverlo\n",
    "        if os.path.exists(ruta_imagen_origen):\n",
    "            # Mueve la imagen a la carpeta de destino\n",
    "            shutil.copy(ruta_imagen_origen, carpeta_destino)\n",
    "            print(f\"Moviendo: {nombre_imagen} a {carpeta_destino}\")\n",
    "        else:\n",
    "            print(f\"No se encontró la imagen: {nombre_imagen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar info_data, se puede cargar ya una columna pixelmetric con la informacion pixel-mm o obtener la metrica pixel desde las imagenes.\n",
    "info_data_df=pd.read_csv(info_data_2022,sep=\"\\t\")\n",
    "# Si las hemos calibrado añadimos CL delante\n",
    "info_data_df['Name_picture'] = info_data_df['Name_picture'].apply(lambda x: 'CL_' + x)\n",
    "info_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain pixel_metric from the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no tienes un modelo para reconocer tu objeto de referencia debes crearlo\n",
    "#Se comienza haciendo particiones de la imagen con la función slicing para introducirlas en CVAT\n",
    "\n",
    "slicing(input_folder=output_calibrated,output_directory=working_directory,\n",
    "        name_slicing=\"gsgsg\", number_pictures=60,\n",
    "          crop=\"left\", slice_height=640, slice_width=640, overlap_height_ratio=0.2, overlap_width_ratio=0.2, crop_level=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posteriormente se tiene que segmentar en CVAT, y ese output se leera para entrenar el modelo y ver si funciona bien, para ello utilizamos la función\n",
    "# train model, pon el archivo.zip en el working directory.\n",
    "\n",
    "coin_model=model_segmentation(working_directory=working_directory)\n",
    "coin_model.train_segmentation_model(input_zip=zip_file_coin, epochs=80,imgsz=640,\n",
    "                                     name_segmentation=\"coin_640px_slices640_26102024_set2023_retina\", pre_model=pre_model\n",
    "                                     , batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tenemos el modelo ya simplemente podemos cargarlo y aplicarlo sobre la carpeta que queramos\n",
    "\n",
    "coin_model_saved=model_segmentation(working_directory=working_directory)\n",
    "contours_coin=coin_model_saved.slice_predict_reconstruct(input_folder=output_calibrated, imgsz=640,\n",
    "                                                         model_path=coin_model_path, slice_height=640, slice_width=640,\n",
    "                                                         overlap_height_ratio=0.2, overlap_width_ratio=0.2,\n",
    "                                                           retina_mask=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_completed=obtain_pixel_metric(info_data=info_data_df, contours=contours_coin,\n",
    "                                         output_directory=working_directory, reference=24.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desagrupar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez hemos completado ya el pixelmetric, si tenemos fotos agrupadas, debemos desagruparlas y conectarlas con su ID\n",
    "#Para posteriormente sacar las medidas que queramos. Esta vez no hacemos slicing, peusto que los grupos son mas grandes que las slcies.\n",
    "# divide_in_sets(input_folder=output_calibrated,output_directory=working_directory, division_name=\"rectangle_group_2023\", number_pictures=100)\n",
    "\n",
    "#Esta vez hacemos solo shell\n",
    "folder_shell=os.path.join(working_directory, \"Seed_2023_set\")\n",
    "divide_in_sets(input_folder=folder_shell,output_directory=working_directory, division_name=\"rectangle_group_2023_seed\", number_pictures=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a entrenar un modelo para que reconozca los grupos\n",
    "\n",
    "group_model=model_segmentation(working_directory=working_directory)\n",
    "group_model.train_segmentation_model(input_zip=zip_file_group, epochs=80,imgsz=1280,\n",
    "                                      name_segmentation=\"rectangle_group_2023set_shell\", pre_model=pre_model, batch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTO DESPUES PARA LOS CONTORNOS EN GROUPED PICTURES\n",
    "\n",
    "# Si tenemos el modelo ya simplemente podemos cargarlo y aplicarlo sobre la carpeta que queramos\n",
    "#Esta funcion se puede optimizar, cuando hay muchas fotos se llena la RAM y va mas lento a partir de las 300 fotos.Habría que hacer tandas, lo que lo peta es la retina mask. \n",
    "group_model_saved=model_segmentation(working_directory=working_directory)\n",
    "contours_groups=group_model_saved.predict_model(model_path=group_model_path_2,\n",
    "                               folder_input=os.path.join(working_directory, \"Seed_2023_set\"),\n",
    "                               imgsz=1600, check_result=False, max_det=2, retina_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora que ya tenemos los contornos, podemos aplicarlo a nuestras imagenes, y tambien coordinaar el info_data_df\n",
    "info_data_completed_path=os.path.join(working_directory, \"info_data_completed_2023.txt\")\n",
    "info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")\n",
    "#PARA QUE FUNCIONE EN 2023 EDITAR EL INFO DATA EN donde pone Sample number cambiar los 0 por 1.\n",
    "info_data_completed.loc[info_data_completed['Sample_number'] == 0, 'Sample_number'] = 1\n",
    "\n",
    "\n",
    "ungroup_pic(input_contours=contours_groups, output_path=working_directory, info_file=info_data_completed, axis=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shell Almonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a entrenar un modelo para las almendras con cascara\n",
    "#Vamos a separar en una carpeta las imagenes de almendras con cascara\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "\n",
    "# Directorio donde están las imágenes\n",
    "directorio_imagenes = f\"{working_directory}/Ungrouped_pics\"  # Cambia esto por la ruta correcta\n",
    "# Directorio de destino donde copiarás las imágenes\n",
    "directorio_destino = f\"{working_directory}/Shell_ungrouped_pics\"\n",
    "\n",
    "# Crear el directorio de destino si no existe\n",
    "os.makedirs(directorio_destino, exist_ok=True)\n",
    "\n",
    "# Copiar las imágenes\n",
    "for index, row in info_data_df.iterrows():\n",
    "    imagen_relativa = row['Sample_picture']  # Obtener la ruta relativa de la imagen\n",
    "    imagen_path = os.path.join(directorio_imagenes, imagen_relativa)  # Ruta completa\n",
    "\n",
    "    try:\n",
    "        # Copiar la imagen al directorio de destino\n",
    "        shutil.copy(imagen_path, os.path.join(directorio_destino, os.path.basename(imagen_path)))\n",
    "        print(f\"Imagen copiada: {imagen_path} a {directorio_destino}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo copiar la imagen {imagen_path}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bien ahora vamos a hacer el slicing y a segmentar y etiquetar las imagenes\n",
    "\n",
    "directorio_imagenes=os.path.join(working_directory, \"Ungrouped_pics_shell_2023\")\n",
    "\n",
    "\n",
    "slicing(input_folder=directorio_imagenes,output_directory=working_directory,name_slicing=\"Slices_for_shell_2023_29102024_320\", number_pictures=50, slice_height=320, slice_width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a entrenar el modelo \n",
    "\n",
    "shell_model=model_segmentation(working_directory=working_directory)\n",
    "shell_model.train_segmentation_model(input_zip=zip_file_shell, epochs=100,imgsz=640, name_segmentation=\"shell_2022_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "#Con watershed\n",
    "\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped_2022.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "\n",
    "shell_masks=shell_masks.slice_predict_reconstruct(input_folder=input_folder,imgsz=320, model_path=shell_model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)\n",
    "shell_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"Shell_2022_08122024_watershed\")\n",
    "shell_object.set_postsegmentation_parameters(sahi=False, segmentation_input=shell_masks, smoothing=True, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "shell_object.measure_almonds(margin=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detectada: NVIDIA GeForce RTX 3060\n",
      "Memoria total de la GPU: 12.00 GB\n",
      "Pic 1/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 2/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 3/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 4/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 5/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 6/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 7/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 8/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 9/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 10/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 11/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 12/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 13/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 14/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 15/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 16/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 17/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 18/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 19/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 20/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 21/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 22/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 23/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 24/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 25/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 26/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 27/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 28/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 29/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 30/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 31/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 32/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 33/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 34/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 35/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 36/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 37/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 38/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 39/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 40/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 41/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 42/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 43/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 44/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 45/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 46/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 47/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 48/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 49/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 50/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 51/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 52/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 53/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 54/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 55/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 56/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 57/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 58/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 59/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 60/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 61/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 62/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 63/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 64/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 65/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 66/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 67/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 68/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 69/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 70/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 71/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 72/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 73/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 74/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 75/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 76/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 77/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 78/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 79/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 80/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 81/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 82/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 83/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 84/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 85/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 86/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 87/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 88/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 89/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 90/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 91/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 92/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 93/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 94/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 95/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 96/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 97/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 98/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 99/100\n",
      "Performing prediction on 36 slices.\n",
      "Pic 100/100\n",
      "Performing prediction on 36 slices.\n",
      "Picture 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:478: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  morphology_table = pd.concat([morphology_table, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with picture CL_02_11_F-004_1.png Fruit number: 21 could not broadcast input array from shape (1000,3028) into shape (1000,1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:494: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_table=pd.concat([general_table,row_general], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 2/100\n",
      "Picture 3/100\n",
      "Picture 4/100\n",
      "Picture 5/100\n",
      "Picture 6/100\n",
      "Picture 7/100\n",
      "Picture 8/100\n",
      "Picture 9/100\n",
      "Picture 10/100\n",
      "Picture 11/100\n",
      "Error with picture CL_02_11_F-010_3.png Fruit number: 16 could not broadcast input array from shape (1000,1016) into shape (1000,8)\n",
      "Picture 12/100\n",
      "Picture 13/100\n",
      "Picture 14/100\n",
      "Picture 15/100\n",
      "Picture 16/100\n",
      "Picture 17/100\n",
      "Picture 18/100\n",
      "Picture 19/100\n",
      "Picture 20/100\n",
      "Picture 21/100\n",
      "Picture 22/100\n",
      "Picture 23/100\n",
      "Picture 24/100\n",
      "Picture 25/100\n",
      "Picture 26/100\n",
      "Picture 27/100\n",
      "Picture 28/100\n",
      "Picture 29/100\n",
      "Picture 30/100\n",
      "Picture 31/100\n",
      "Picture 32/100\n",
      "Picture 33/100\n",
      "Picture 34/100\n",
      "Picture 35/100\n",
      "Picture 36/100\n",
      "Picture 37/100\n",
      "Picture 38/100\n",
      "Picture 39/100\n",
      "Picture 40/100\n",
      "Picture 41/100\n",
      "Picture 42/100\n",
      "Picture 43/100\n",
      "Picture 44/100\n",
      "Picture 45/100\n",
      "Picture 46/100\n",
      "Picture 47/100\n",
      "Picture 48/100\n",
      "Picture 49/100\n",
      "Picture 50/100\n",
      "Picture 51/100\n",
      "Picture 52/100\n",
      "Picture 53/100\n",
      "Picture 54/100\n",
      "Picture 55/100\n",
      "Picture 56/100\n",
      "Picture 57/100\n",
      "Picture 58/100\n",
      "Picture 59/100\n",
      "Picture 60/100\n",
      "Picture 61/100\n",
      "Picture 62/100\n",
      "Picture 63/100\n",
      "Picture 64/100\n",
      "Picture 65/100\n",
      "Picture 66/100\n",
      "Picture 67/100\n",
      "Picture 68/100\n",
      "Error with picture CL_03_11_F-003_1.png Fruit number: 14 could not broadcast input array from shape (1000,1261) into shape (1000,131)\n",
      "Picture 69/100\n",
      "Picture 70/100\n",
      "Picture 71/100\n",
      "Picture 72/100\n",
      "Picture 73/100\n",
      "Picture 74/100\n",
      "Picture 75/100\n",
      "Picture 76/100\n",
      "Picture 77/100\n",
      "Picture 78/100\n",
      "Picture 79/100\n",
      "Error with picture CL_03_11_F-013_4.png Fruit number: 5 could not broadcast input array from shape (1000,1440) into shape (1000,220)\n",
      "Picture 80/100\n",
      "Picture 81/100\n",
      "Picture 82/100\n",
      "Picture 83/100\n",
      "Picture 84/100\n",
      "Picture 85/100\n",
      "Picture 86/100\n",
      "Picture 87/100\n",
      "Picture 88/100\n",
      "Picture 89/100\n",
      "Picture 90/100\n",
      "Picture 91/100\n",
      "Picture 92/100\n",
      "Picture 93/100\n",
      "Picture 94/100\n",
      "Picture 95/100\n",
      "Picture 96/100\n",
      "Picture 97/100\n",
      "Picture 98/100\n",
      "Picture 99/100\n",
      "Picture 100/100\n",
      "[['CL_02_11_F-004_1.png', 21, ValueError('could not broadcast input array from shape (1000,3028) into shape (1000,1000)')], ['CL_02_11_F-010_3.png', 16, ValueError('could not broadcast input array from shape (1000,1016) into shape (1000,8)')], ['CL_03_11_F-003_1.png', 14, ValueError('could not broadcast input array from shape (1000,1261) into shape (1000,131)')], ['CL_03_11_F-013_4.png', 5, ValueError('could not broadcast input array from shape (1000,1440) into shape (1000,220)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:541: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_table['Binary_mask_picture'] = binary_table['Sample_picture'] + '_' + binary_table['Fruit_number'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "#Con sahi\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped_2022.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "shell_masks=shell_masks.predict_model_sahi(model_path=shell_model_path, check_result=False, folder_input=input_folder,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"NMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)\n",
    "shell_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"Shell_2022_09122024_sahi\")\n",
    "shell_object.set_postsegmentation_parameters(sahi=True, segmentation_input=shell_masks)\n",
    "shell_object.measure_almonds(margin=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Almonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a entrenar un modelo para las almendras sin cascara\n",
    "#Vamos a separar en una carpeta las imagenes de almendras sin cascara\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"No\"]\n",
    "\n",
    "# Directorio donde están las imágenes\n",
    "directorio_imagenes = f\"{working_directory}/Ungrouped_pics\"  # Cambia esto por la ruta correcta\n",
    "# Directorio de destino donde copiarás las imágenes\n",
    "directorio_destino = f\"{working_directory}/Seed_ungrouped_pics\"\n",
    "\n",
    "# Crear el directorio de destino si no existe\n",
    "os.makedirs(directorio_destino, exist_ok=True)\n",
    "\n",
    "# Copiar las imágenes\n",
    "for index, row in info_data_df.iterrows():\n",
    "    imagen_relativa = row['Sample_picture']  # Obtener la ruta relativa de la imagen\n",
    "    imagen_path = os.path.join(directorio_imagenes, imagen_relativa)  # Ruta completa\n",
    "\n",
    "    try:\n",
    "        # Copiar la imagen al directorio de destino\n",
    "        shutil.copy(imagen_path, os.path.join(directorio_destino, os.path.basename(imagen_path)))\n",
    "        print(f\"Imagen copiada: {imagen_path} a {directorio_destino}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo copiar la imagen {imagen_path}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicing(input_folder=directorio_destino,output_directory=working_directory,name_slicing=\"Slices_for_seed_21102024_320\", number_pictures=30, slice_height=320, slice_width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_model=model_segmentation(working_directory=working_directory)\n",
    "seed_model.train_segmentation_model(input_zip=zip_file_seed, epochs=100,imgsz=640, name_segmentation=\"seed_2022_211024\",\n",
    "                                      pre_model=pre_model, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"No\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "seed_masks=model_segmentation(working_directory=working_directory)\n",
    "seed_masks=shell_masks.slice_predict_reconstruct(input_folder=input_folder,imgsz=640, model_path=shell_model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)\n",
    "seed_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Seed_almond\", binary_masks=True, project_name=\"Seed_2022_21102022\",\n",
    "                        segmentation_maks=shell_masks, smoothing=True, smoothing_iterations=2, kernel_smoothing=5,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.5)\n",
    "seed_object.measure_almonds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "#Con sahi\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped_2022.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"No\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba_seed_2022\")\n",
    "seed_masks=model_segmentation(working_directory=working_directory)\n",
    "seed_masks=seed_masks.predict_model_sahi(model_path=seed_model_path, check_result=False, folder_input=input_folder,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.3,\n",
    "                                                overlap_width_ratio=0.3, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)\n",
    "seed_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Seed_almond\", binary_masks=False, project_name=\"seed_2022_congreso_frutadehueso\")\n",
    "seed_object.set_postsegmentation_parameters(sahi=True, segmentation_input=seed_masks)\n",
    "seed_object.measure_almonds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_masks=\"C:/Users/Pheno/Documents/database_almondcv2/Momocs/input\"\n",
    "info_data_masks=\"C:/Users/Pheno/Documents/database_almondcv2/Momocs/input/binary_masks_info_table.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero hay que ejecutar un script para instalar las librerías necesarias\n",
    "install_morphometrics_packages_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisis exploratorio para decidir nharmonics\n",
    "exploratory_morphometrics_r(info_data=info_data_masks, grouping_factor=\"ID\", directorio_input=input_masks,\n",
    "                             output_directory=working_directory, show=True, nharmonics=10,nexamples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta=os.path.join(working_directory,\"exploratory_plots\",\"outlines_objects.rds\")\n",
    "run_efourier_pca_morphometrics_r(ruta_outline_objects=ruta, nharmonics=10, output_directory=working_directory, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta=os.path.join(working_directory,\"efourier_results\",\"pca_fourier.rds\")\n",
    "run_plot_pca_morphometrics_r(ruta_pca_objects=ruta, output_directory=working_directory, grouping_factor=\"ID\", chull_layer=\"TRUE\", chullfilled_layer=\"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta=os.path.join(working_directory,\"efourier_results\",\"pca_fourier.rds\")\n",
    "run_kmeans_efourier_r(ruta_pca_objects=ruta, output_directory=working_directory,max_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_1=os.path.join(working_directory,\"efourier_results\",\"pca_fourier.rds\")\n",
    "ruta_2=os.path.join(working_directory,\"kmeans_results\",\"kmeans_pca_fourier_5.rds\")\n",
    "run_obtain_kmeans_classification_r(ruta_pca_objects=ruta_1, output_directory=working_directory, ruta_kmeans_objects=ruta_2,\n",
    "                                   chull_layer=\"TRUE\", chullfilled_layer=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUCIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROTAR \n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Ruta de la carpeta con las imágenes\n",
    "folder_path = output_calibrated\n",
    "\n",
    "# Recorrer cada archivo en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):  # Filtrar solo archivos de imagen\n",
    "        # Ruta completa del archivo\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Abrir la imagen\n",
    "        with Image.open(img_path) as img:\n",
    "            # Rotar la imagen 90 grados en sentido contrario a las agujas del reloj\n",
    "            rotated_img = img.rotate(90, expand=True)\n",
    "            \n",
    "            # Sobrescribir la imagen rotada en la misma ubicación\n",
    "            rotated_img.save(img_path)\n",
    "\n",
    "print(\"Rotación y guardado completados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quiero separar en dos carpetas shell y no shell\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Cargar el DataFrame (asegúrate de cambiar 'ruta_al_archivo' por la ruta de tu archivo)\n",
    "df = pd.read_csv(info_data,sep=\"\\t\")\n",
    "\n",
    "# Definir las carpetas de origen y destino\n",
    "carpeta_origen = output_calibrated\n",
    "carpeta_destino_yes = os.path.join(working_directory, \"Shell_2023_set\")\n",
    "carpeta_destino_no = os.path.join(working_directory, \"Seed_2023_set\")\n",
    "\n",
    "# Crear las carpetas de destino si no existen\n",
    "os.makedirs(carpeta_destino_yes, exist_ok=True)\n",
    "os.makedirs(carpeta_destino_no, exist_ok=True)\n",
    "\n",
    "# Iterar sobre las filas del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    nombre_imagen = row['Name_picture']  # Cambia 'NombreImagen' al nombre de la columna en tu DataFrame\n",
    "    shell_value = row['Shell']           # Cambia 'Shell' al nombre exacto de la columna en tu DataFrame\n",
    "    nombre_imagen = f\"CL_{nombre_imagen}\"\n",
    "    # Definir la ruta completa de la imagen en la carpeta de origen\n",
    "    ruta_origen = os.path.join(carpeta_origen, nombre_imagen)\n",
    "    \n",
    "    # Comprobar si el valor de Shell es 'Yes' o 'No' y definir la carpeta de destino\n",
    "    if shell_value == 'Yes':\n",
    "        ruta_destino = os.path.join(carpeta_destino_yes, nombre_imagen)\n",
    "    elif shell_value == 'No':\n",
    "        ruta_destino = os.path.join(carpeta_destino_no, nombre_imagen)\n",
    "    else:\n",
    "        continue  # Saltar filas con otros valores en 'Shell'\n",
    "    \n",
    "    # Copiar la imagen a la carpeta de destino correspondiente\n",
    "    try:\n",
    "        shutil.copy(ruta_origen, ruta_destino)\n",
    "        print(f\"Imagen '{nombre_imagen}' copiada a {ruta_destino}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Imagen '{nombre_imagen}' no encontrada en {ruta_origen}\")\n",
    "\n",
    "print(\"Copia de imágenes completada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_model_path=os.path.join(models_directory, \"prueba_Retina_mask_640_shell.pt\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "shell_masks=shell_masks.slice_predict_reconstruct(input_folder=input_folder,imgsz=640, model_path=shell_model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2, retina_mask=True)\n",
    "shell_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"pruebas_retina_mask\",\n",
    "                        segmentation_maks=shell_masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=5,\n",
    "                        watershed=False, kernel_watershed=5, threshold_watershed=0.5)\n",
    "shell_object.measure_almonds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped_2022.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_model_path=os.path.join(models_directory, \"prueba_Retina_mask_320_shell.pt\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "shell_masks=shell_masks.predict_model_sahi(model_path=shell_model_path, check_result=True, folder_input=input_folder,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.3,\n",
    "                                                overlap_width_ratio=0.3, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.9,\n",
    "                                                  imgsz=320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped_2022.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_model_path=os.path.join(models_directory, \"prueba_Retina_mask_320_shell.pt\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "shell_masks=shell_masks.predict_model_sahi(model_path=shell_model_path, check_result=True, folder_input=input_folder,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.3, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.9,\n",
    "                                                  imgsz=320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids_df = info_data_completed[~info_data_completed['ID'].str.lower().duplicated(keep=False)]\n",
    "unique_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = info_data_completed[info_data_completed['Shell'] == \"No\"]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEED MODEL 2023\n",
    "zip_file=os.path.join(working_directory,\"seed_320_2023_29102024.zip\")\n",
    "model=model_segmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file, epochs=100,imgsz=320,\n",
    "                                name_segmentation=\"seed_2023_320_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16, retina_masks=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shell MODEL 2023\n",
    "zip_file=os.path.join(working_directory,\"shell_2023_320.zip\")\n",
    "model=model_segmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file, epochs=100,imgsz=320,\n",
    "                                name_segmentation=\"shell_2023_320_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16, retina_masks=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed MODEL 2022\n",
    "zip_file=os.path.join(working_directory,\"seed_2022_21102024.zip\")\n",
    "model=model_segmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file, epochs=100,imgsz=320,\n",
    "                                name_segmentation=\"seed_2022_320_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16, retina_masks=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shell MODEL 2022\n",
    "zip_file=os.path.join(working_directory,\"shell_2022_320.zip\")\n",
    "model=model_segmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file, epochs=100,imgsz=320,\n",
    "                                name_segmentation=\"shell_2022_320_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16, retina_masks=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coin model 2022\n",
    "zip_file=os.path.join(working_directory,\"coin_640_21102024.zip\")\n",
    "model=model_segmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file, epochs=100,imgsz=640,\n",
    "                                name_segmentation=\"coin_2022_640_yolov11\",\n",
    "                                      pre_model=pre_model, batch=8, retina_masks=True)\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prepare dataset for pose estimation\n",
    "pose_preparation=model_segmentation(working_directory=working_directory)\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba_2023\")\n",
    "pose_preparation=pose_preparation.predict_model_sahi(model_path=shell_model_path, check_result=False, folder_input=input_folder,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.3,\n",
    "                                                overlap_width_ratio=0.3, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                 imgsz=320)\n",
    "\n",
    "prepare_pose_dataset(segmentation_input=pose_preparation, output_directory=working_directory, output_name=\"prueba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pose_model=model_segmentation(working_directory=working_directory)\n",
    "zip_file_pose=os.path.join(working_directory, \"shell_2023_tip_pose_07112024.zip\")\n",
    "pre_model=os.path.join(models_directory,\"yolo11s-pose.pt\")\n",
    "pose_model.train_segmentation_model(input_zip=zip_file_pose, epochs=100,imgsz=256, name_segmentation=\"shell_2023_yolov11s_pose_2\",\n",
    "                                     pre_model=pre_model, batch=16, pose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Define la ruta donde quieres guardar la imagen\n",
    "ruta_imagen = 'C:/Users/Pheno/Documents/database_almondcv2/grafica.png'\n",
    "\n",
    "# Comando R para generar el gráfico y guardarlo en un archivo PNG\n",
    "command = f\"\"\"\n",
    "Rscript -e \"\n",
    "# Crear un vector de datos\n",
    "x <- c(1, 2, 3, 4, 5)\n",
    "y <- c(1, 4, 9, 16, 25)\n",
    "\n",
    "# Iniciar el dispositivo gráfico PNG y guardar la imagen en la ruta indicada\n",
    "png('{ruta_imagen}')\n",
    "\n",
    "# Crear el gráfico\n",
    "plot(x, y, main='Gráfico de ejemplo', xlab='X', ylab='Y')\n",
    "\n",
    "# Cerrar el dispositivo gráfico\n",
    "dev.off()\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el comando R usando subprocess\n",
    "result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Verificar si hubo algún error\n",
    "if result.stderr:\n",
    "    print(\"Error:\", result.stderr.decode())\n",
    "else:\n",
    "    print(\"El script R se ejecutó correctamente.\")\n",
    "\n",
    "    # Leer y mostrar la imagen generada por R en Python\n",
    "    img = mpimg.imread(ruta_imagen)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')  # Desactivar los ejes si es necesario\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta al archivo de script de R\n",
    "ruta_script_r = r'C:\\Users\\Pheno\\prueba.R'\n",
    "\n",
    "# Definir el comando para ejecutar el script de R\n",
    "command = f'Rscript \"{ruta_script_r}\"'\n",
    "\n",
    "# Ejecutar el comando con subprocess\n",
    "try:\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Mostrar la salida del comando R\n",
    "    print(\"Salida del comando R:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    # Mostrar cualquier error si ocurre\n",
    "    if result.stderr:\n",
    "        print(\"Error:\")\n",
    "        print(result.stderr)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error al ejecutar el script R: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta al script de R\n",
    "ruta_script_r = \"C:/Users/Pheno/prueba.R\"\n",
    "\n",
    "# Ejecutar el script de R utilizando subprocess\n",
    "try:\n",
    "    # Si tienes Rscript, puedes usarlo directamente\n",
    "    result = subprocess.run(['Rscript', ruta_script_r], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(f\"Output del script de R:\\n{result.stdout.decode()}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error al ejecutar el script de R:\\n{e.stderr.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Ruta al archivo de script de R\n",
    "ruta_script_r = r'C:\\Users\\Pheno\\prueba.R'\n",
    "\n",
    "# Definir el comando para ejecutar el script de R\n",
    "command = f'Rscript \"{ruta_script_r}\"'\n",
    "\n",
    "# Ruta de salida del archivo gráfico generado\n",
    "ruta_imagen = r'C:\\Users\\Pheno\\HOLA.png'\n",
    "\n",
    "# Ejecutar el comando con subprocess\n",
    "try:\n",
    "    # Ejecutar el script R\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Mostrar la salida del comando R\n",
    "    print(\"Salida del comando R:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    # Mostrar cualquier error si ocurre\n",
    "    if result.stderr:\n",
    "        print(\"Error:\")\n",
    "        print(result.stderr)\n",
    "\n",
    "    # Esperar un poco para asegurarse de que la imagen se haya guardado\n",
    "    time.sleep(2)  # Esperar 2 segundos (ajustable si es necesario)\n",
    "\n",
    "    # Verificar si la imagen fue generada\n",
    "    if os.path.exists(ruta_imagen):\n",
    "        print(f\"La imagen fue generada correctamente en {ruta_imagen}\")\n",
    "        \n",
    "        # Abrir y mostrar la imagen en Python usando PIL y matplotlib\n",
    "        img = Image.open(ruta_imagen)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # Desactivar los ejes\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No se pudo encontrar la imagen generada.\")\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error al ejecutar el script R: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta de la imagen que deseas mostrar\n",
    "ruta_imagen = r'C:\\Users\\Pheno\\HOLA.png'  # Sustituye por tu ruta\n",
    "\n",
    "# Abrir la imagen con PIL\n",
    "img = Image.open(ruta_imagen)\n",
    "\n",
    "# Mostrar la imagen con matplotlib\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Desactivar los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Definir el comando de R para imprimir el directorio de trabajo\n",
    "command = \"\"\"\n",
    "Rscript -e\n",
    "\"\"\"\n",
    "script=\"\"\"# Intentar imprimir el directorio de trabajo\n",
    "# cat('Directorio de trabajo de R: ', getwd(), '\\\\n')\"\"\"\n",
    "\n",
    "# Ejecutar el comando con subprocess\n",
    "try:\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Mostrar la salida del comando\n",
    "    print(\"Salida del comando R:\")\n",
    "    print(result.stdout)  # Mostrar la salida de R (el directorio de trabajo de R)\n",
    "\n",
    "    # Mostrar cualquier error si ocurre\n",
    "    if result.stderr:\n",
    "        print(\"Error:\")\n",
    "        print(result.stderr)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error al ejecutar el comando R: {e.stderr}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
