{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch images processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from calibrations import calibrate_color, build_calibration, calibrate_distortion, calibrate_color_and_distortion\n",
    "import os\n",
    "from plantcv import plantcv as pcv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from aux_functions import slicing, obtain_pixel_metric, divide_in_sets, ungroup_pic\n",
    "from model_class import model_segmentation\n",
    "from pictures_class import pictures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "raw_folder=\"C:/Users/Pheno/Documents/database_almondcv2/all_sessions/\"\n",
    "chessboards=\"C:/Users/Pheno/Documents/database_almondcv2/calibracion/chessboards\"\n",
    "mtx_input_path=os.path.join(chessboards,\"calibration_mtx.npz\") ## for distorsion\n",
    "standard_matrix_color=\"C:/Users/Pheno/Documents/database_almondcv2/all_sessions/02_11_F-010.JPG\" ### a picture to select if some pictures produces errors in color \n",
    "info_data=\"C:/Users/Pheno/Documents/database_almondcv2/info_data.txt\"\n",
    "models_directory=\"C:/Users/Pheno/Documents/database_almondcv2/models/\"\n",
    "pre_model=os.path.join(models_directory, \"yolov8n-seg.pt\")\n",
    "group_model_path=os.path.join(models_directory, \"rectangles_yolo_11s_04102024.pt\")\n",
    "shell_model_path=os.path.join(models_directory, \"shell_320slides_imgsz_640_yolov8n.pt\")\n",
    "zip_file_coin=os.path.join(working_directory,\"coin_seg_640_04102024.zip\")\n",
    "zip_file_group=os.path.join(working_directory,\"rectangles_seg_04102024.zip\")\n",
    "zip_file_shell=os.path.join(working_directory,\"slices_mixpx_12102024.zip\")\n",
    "#outputs\n",
    "output=\"C:/Users/Pheno/Documents/database_almondcv2\"\n",
    "output_calibrated=os.path.join(output,\"calibrated_pics/\")\n",
    "os.makedirs(output_calibrated, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color and distorsion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to create distortion model\n",
    "build_calibration(chessboardSize=(6, 8), frameSize=(5472,3648), dir_path=chessboards, \n",
    "                  image_format=\".jpg\", size_of_chessboard_squares_mm=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora mismo esta puesto en modo calibracion los errores utilizando una foto como referencia, para calibracion normal quitar la standard_matrix_color\n",
    "calibrate_color_and_distortion(raw_folder=raw_folder,mtx_input_path=mtx_input_path,output_calibrated=output_calibrated, radius_param=10, standard_matrix=standard_matrix_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHUNK para mover automaticamente lo que este en la lista errores a donde tu queiras\n",
    "#first we move \n",
    "\n",
    "carpeta_destino = os.path.join(raw_folder,\"errores\")    # Cambia esto por la ruta correcta\n",
    "\n",
    "# Crea la carpeta de destino si no existe\n",
    "os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "\n",
    "# Lee el archivo de texto con los nombres de las imágenes\n",
    "with open(os.path.join(output_calibrated,\"errors_in_calibrations.txt\"), \"r\") as archivo:\n",
    "    for nombre_imagen in archivo:\n",
    "        nombre_imagen = nombre_imagen.strip()  # Elimina espacios en blanco y saltos de línea\n",
    "        ruta_imagen_origen = os.path.join(raw_folder, nombre_imagen)\n",
    "        \n",
    "        # Verifica si el archivo existe antes de moverlo\n",
    "        if os.path.exists(ruta_imagen_origen):\n",
    "            # Mueve la imagen a la carpeta de destino\n",
    "            shutil.copy(ruta_imagen_origen, carpeta_destino)\n",
    "            print(f\"Moviendo: {nombre_imagen} a {carpeta_destino}\")\n",
    "        else:\n",
    "            print(f\"No se encontró la imagen: {nombre_imagen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar info_data, se puede cargar ya una columna pixelmetric con la informacion pixel-mm o obtener la metrica pixel desde las imagenes.\n",
    "info_data_df=pd.read_csv(info_data,sep=\"\\t\")\n",
    "info_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain pixel_metric from the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no tienes un modelo para reconocer tu objeto de referencia debes crearlo\n",
    "#Se comienza haciendo particiones de la imagen con la función slicing para introducirlas en CVAT\n",
    "\n",
    "slicing(input_folder=output_calibrated,output_directory=working_directory,name_slicing=\"Slices_for_coin_03102024\", number_pictures=60, crop=\"left\", slice_height=640, slice_width=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posteriormente se tiene que segmentar en CVAT, y ese output se leera para entrenar el modelo y ver si funciona bien, para ello utilizamos la función\n",
    "# train model, pon el archivo.zip en el working directory.\n",
    "\n",
    "coin_model=model_segmentation(working_directory=working_directory)\n",
    "coin_model.train_segmentation_model(input_zip=zip_file_coin, epochs=80,imgsz=640, name_segmentation=\"coin_640\", pre_model=pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tenemos el modelo ya simplemente podemos cargarlo y aplicarlo sobre la carpeta que queramos\n",
    "model_path=os.path.join(models_directory,\"coin_yolo_11s_041022024.pt\")\n",
    "coin_model_saved_sahi=model_segmentation(working_directory=working_directory)\n",
    "contours_coin=coin_model_saved_sahi.predict_model_sahi(model_path=model_path,\n",
    "                                                       folder_input=\"C:/Users/Pheno/Documents/database_almondcv2/calibrated_pics/\",\n",
    "                                                       slice_height=640, slice_width=640, check_result=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_completed=obtain_pixel_metric(info_data=info_data_df, contours=contours_coin,\n",
    "                                         output_directory=working_directory, reference=24.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desagrupar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez hemos completado ya el pixelmetric, si tenemos fotos agrupadas, debemos desagruparlas y conectarlas con su ID\n",
    "#Para posteriormente sacar las medidas que queramos. Esta vez no hacemos slicing, peusto que los grupos son mas grandes que las slcies.\n",
    "divide_in_sets(input_folder=output_calibrated,output_directory=working_directory, division_name=\"rectangle_group\", number_pictures=60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a entrenar un modelo para que reconozca los grupos\n",
    "\n",
    "group_model=model_segmentation(working_directory=working_directory)\n",
    "group_model.train_segmentation_model(input_zip=zip_file_group, epochs=100,imgsz=1280,\n",
    "                                      name_segmentation=\"rectangle_group\", pre_model=pre_model, batch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTO DESPUES PARA LOS CONTORNOS EN GROUPED PICTURES\n",
    "\n",
    "# Si tenemos el modelo ya simplemente podemos cargarlo y aplicarlo sobre la carpeta que queramos\n",
    "\n",
    "group_model_saved=model_segmentation(working_directory=working_directory)\n",
    "contours_groups=group_model_saved.predict_model(model_path=group_model_path,\n",
    "                               folder_input=output_calibrated,\n",
    "                               imgsz=1280, check_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora que ya tenemos los contornos, podemos aplicarlo a nuestras imagenes, y tambien coordinaar el info_data_df\n",
    "# info_data_completed_path=os.path.join(working_directory, \"info_data_completed.txt\")\n",
    "# info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")\n",
    "ungroup_pic(input_contours=contours_groups, output_path=working_directory, info_file=info_data_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a entrenar un modelo para las almendras con cascara\n",
    "#Vamos a separar en una carpeta las imagenes de almendras con cascara\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "\n",
    "# Directorio donde están las imágenes\n",
    "directorio_imagenes = f\"{working_directory}/Ungrouped_pics\"  # Cambia esto por la ruta correcta\n",
    "# Directorio de destino donde copiarás las imágenes\n",
    "directorio_destino = f\"{working_directory}/Shell_ungrouped_pics\"\n",
    "\n",
    "# Crear el directorio de destino si no existe\n",
    "os.makedirs(directorio_destino, exist_ok=True)\n",
    "\n",
    "# Copiar las imágenes\n",
    "for index, row in info_data_df.iterrows():\n",
    "    imagen_relativa = row['Sample_picture']  # Obtener la ruta relativa de la imagen\n",
    "    imagen_path = os.path.join(directorio_imagenes, imagen_relativa)  # Ruta completa\n",
    "\n",
    "    try:\n",
    "        # Copiar la imagen al directorio de destino\n",
    "        shutil.copy(imagen_path, os.path.join(directorio_destino, os.path.basename(imagen_path)))\n",
    "        print(f\"Imagen copiada: {imagen_path} a {directorio_destino}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo copiar la imagen {imagen_path}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bien ahora vamos a hacer el slicing y a segmentar y etiquetar las imagenes\n",
    "\n",
    "slicing(input_folder=directorio_destino,output_directory=working_directory,name_slicing=\"Slices_for_shell_10102024_320\", number_pictures=25, slice_height=320, slice_width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a entrenar el modelo \n",
    "\n",
    "shell_model=model_segmentation(working_directory=working_directory)\n",
    "shell_model.train_segmentation_model(input_zip=zip_file_shell, epochs=50,imgsz=640, name_segmentation=\"shell_pxmx_121024\",\n",
    "                                      pre_model=pre_model, batch=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2024 11:35:54 - INFO - sahi.slicing -   image.shape: (757, 2901)\n",
      "10/14/2024 11:35:54 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detectada: NVIDIA GeForce RTX 3060\n",
      "Memoria total de la GPU: 12.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2024 11:35:58 - INFO - sahi.slicing -   image.shape: (757, 2985)\n",
      "10/14/2024 11:35:58 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n",
      "10/14/2024 11:36:03 - INFO - sahi.slicing -   image.shape: (757, 2968)\n",
      "10/14/2024 11:36:03 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n",
      "10/14/2024 11:36:07 - INFO - sahi.slicing -   image.shape: (774, 2951)\n",
      "10/14/2024 11:36:07 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n",
      "10/14/2024 11:36:11 - INFO - sahi.slicing -   image.shape: (757, 2951)\n",
      "10/14/2024 11:36:11 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almond_cv2\\pictures_class.py:292: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  morphology_table = pd.concat([morphology_table, row], ignore_index=True)\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almond_cv2\\pictures_class.py:308: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_table=pd.concat([general_table,row_general], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Ahora podemos utilizar ya el modelo y la clase picture para obtener todas las medidas\n",
    "\n",
    "info_data_df=pd.read_csv(f\"{working_directory}/info_data_completed_ungrouped.txt\", sep=\"\\t\")\n",
    "info_data_df = info_data_df[info_data_df[\"Shell\"] == \"Yes\"]\n",
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "shell_masks=model_segmentation(working_directory=working_directory)\n",
    "shell_masks=shell_masks.slice_predict_reconstruct(input_folder=input_folder,imgsz=640, model_path=shell_model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)\n",
    "shell_object=pictures(working_directory=working_directory, input_folder=input_folder,info_file=info_data_df,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"Shell_2022_13102024_smooth_5, watershed\",\n",
    "                        segmentation_maks=shell_masks, smoothing=True, smoothing_iterations=2, kernel_smoothing=5,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.5)\n",
    "shell_object.measure_almonds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUCIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder=os.path.join(working_directory, \"fotos_prueba\")\n",
    "prueba1=model_segmentation(working_directory=working_directory)\n",
    "prueba2=prueba1.slice_predict_reconstruct(input_folder=input_folder,imgsz=640, model_path=shell_model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba2[200][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sahi.slicing import slice_image\n",
    "image_path=standard_matrix_color\n",
    "image_selected = Image.open(image_path)\n",
    "image_sliced=slice_image(image=image_selected, slice_width=640,\n",
    "                        slice_height=640,overlap_height_ratio=0.2,\n",
    "                        overlap_width_ratio=0.2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sliced.original_image_height"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
