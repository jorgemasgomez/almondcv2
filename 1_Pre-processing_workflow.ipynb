{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from calibrations import  build_calibration, calibrate_color_and_distortion, calibrate_color, calibrate_distortion\n",
    "from aux_functions import obtain_pixel_metric, ungroup_pic\n",
    "from model_class import ModelSegmentation\n",
    "import pandas as pd\n",
    "\n",
    "#Set paths of the files\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "chessboards=os.path.join(working_directory, \"calibracion/chessboards\") #folder with chessboard pitcures\n",
    "raw_folder=os.path.join(working_directory,\"pruebas_jorge\")#folder with the pictures to calibrate\n",
    "mtx_input_path=os.path.join(chessboards,\"calibration_mtx.npz\") #for distortion in npz format\n",
    "standard_matrix_color=os.path.join(working_directory, \"pruebas_jorge/17_11_F-025.JPG\") #picture of reference\n",
    "output_calibrated=os.path.join(working_directory,\"pruebas_jorge\") #output folder for calibrated pictures\n",
    "\n",
    "coin_model_path=os.path.join(working_directory,\"models/coin_2022_yolov11_640.pt\")\n",
    "info_table=os.path.join(working_directory,\"info_data.txt\")\n",
    "\n",
    "group_model_path=os.path.join(working_directory, \"models/rectangle_2022_yolov11s_1280.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color and Distortion calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First build your distortion model based in chessboards\n",
    "build_calibration(chessboardSize=(6, 8), frameSize=(5472,3648), dir_path=chessboards, \n",
    "                  image_format=\".jpg\", size_of_chessboard_squares_mm=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calibrate color and distortion\n",
    "calibrate_color_and_distortion(raw_folder=raw_folder,mtx_input_path=mtx_input_path,output_calibrated=output_calibrated,\n",
    "                                radius_param=10, standard_matrix=standard_matrix_color) #Standard matrix is a picture of reference to use instead of the original picture for error cases or simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calibrate distortion only\n",
    "\n",
    "calibrate_distortion(input_folder=raw_folder, mtx_input=mtx_input_path, output_path=output_calibrated, input_picture=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard matrix\n",
      "Some problem with picture C:/Users/Pheno/Documents/database_almondcv2/pruebas_jorge\\CL_28_10_CG-009.JPG\n",
      "[Errno 2] No such file or directory: 'C:/Users/Pheno/Documents/database_almondcv2/pruebas_jorge/28_10_CG-009.JPG'\n",
      "Using standard matrix\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Pheno/Documents/database_almondcv2/pruebas_jorge/28_10_CG-009.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\calibrations.py:44\u001b[0m, in \u001b[0;36mcalibrate_color\u001b[1;34m(input_picture, input_folder, output_path, approach, radius_parameter, standard_matrix, force_standard_matrix)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing standard matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m standard_matrix_pic, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandard_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m card_mask \u001b[38;5;241m=\u001b[39m pcv\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mdetect_color_card(rgb_img\u001b[38;5;241m=\u001b[39mstandard_matrix_pic, radius\u001b[38;5;241m=\u001b[39mradius_parameter)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\plantcv\\plantcv\\readimage.py:44\u001b[0m, in \u001b[0;36mreadimage\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Default to drop alpha channel if user doesn't specify 'rgba'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mRead an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Pheno/Documents/database_almondcv2/pruebas_jorge/28_10_CG-009.JPG'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Function for calibrate color only\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcalibrate_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_calibrated\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstandard_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandard_matrix_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mforce_standard_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#force_standard_matrix option uses in all the pictures the reference picture. In negative case, use only standard_matrix in error cases.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\calibrations.py:60\u001b[0m, in \u001b[0;36mcalibrate_color\u001b[1;34m(input_picture, input_folder, output_path, approach, radius_parameter, standard_matrix, force_standard_matrix)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m standard_matrix:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing standard matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m     standard_matrix_pic, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandard_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     card_mask \u001b[38;5;241m=\u001b[39m pcv\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mdetect_color_card(rgb_img\u001b[38;5;241m=\u001b[39mstandard_matrix_pic, radius\u001b[38;5;241m=\u001b[39mradius_parameter)\n\u001b[0;32m     62\u001b[0m     headers, card_matrix \u001b[38;5;241m=\u001b[39m pcv\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mget_color_matrix(rgb_img\u001b[38;5;241m=\u001b[39mstandard_matrix_pic, mask\u001b[38;5;241m=\u001b[39mcard_mask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\plantcv\\plantcv\\readimage.py:44\u001b[0m, in \u001b[0;36mreadimage\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Default to drop alpha channel if user doesn't specify 'rgba'\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(img)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(img)[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNATIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Pheno/Documents/database_almondcv2/pruebas_jorge/28_10_CG-009.JPG'"
     ]
    }
   ],
   "source": [
    "#Function for calibrate color only\n",
    "\n",
    "calibrate_color(input_folder=raw_folder, output_path=output_calibrated,standard_matrix=standard_matrix_color,\n",
    "                 force_standard_matrix=\"No\")  #force_standard_matrix option uses in all the pictures the reference picture. In negative case, use only standard_matrix in error cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy the model \n",
    "\n",
    "reference_model=ModelSegmentation(working_directory=working_directory)\n",
    "contours_coin=reference_model.slice_predict_reconstruct(input_folder=output_calibrated, imgsz=640,\n",
    "                                                         model_path=coin_model_path, slice_height=640, slice_width=640,\n",
    "                                                         overlap_height_ratio=0.1, overlap_width_ratio=0.1,\n",
    "                                                           retina_mask=True, conf=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load info table\n",
    "info_data_df=pd.read_csv(info_table,sep=\"\\t\")\n",
    "# If we use a calibrated dataset but the info table was previous we can include CL_ automatically with this line\n",
    "# info_data_df['Name_picture'] = info_data_df['Name_picture'].apply(lambda x: 'CL_' + x)\n",
    "\n",
    "info_data_completed=obtain_pixel_metric(info_data=info_data_df, contours=contours_coin,\n",
    "                                         output_directory=working_directory, reference=24.25) #reference in mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ungroup pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load group model\n",
    "group_model=ModelSegmentation(working_directory=working_directory)\n",
    "contours_groups=group_model.predict_model(model_path=group_model_path,\n",
    "                               folder_input=output_calibrated,\n",
    "                               imgsz=1280, check_result=False, max_det=2, retina_mask=False) #Retina mask not recommended here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain sample pictures and update info table. \n",
    "info_data_completed_path=os.path.join(working_directory, \"info_data_completed_2022 (2).txt\")\n",
    "info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")\n",
    "\n",
    "ungroup_pic(input_contours=contours_groups, output_path=working_directory, info_file=info_data_completed, axis=\"X\") #axis indicate if the samples should be order according to Y or X axis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
