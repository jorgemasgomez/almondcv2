{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Develop your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation\n",
    "from aux_functions import slicing\n",
    "import cv2\n",
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "pictures_directory=os.path.join(working_directory, \"fotos_prueba_seed_2022\")\n",
    "pre_model=os.path.join(working_directory, \"models/yolo11s-seg.pt\")\n",
    "model_path=os.path.join(working_directory, \"models/seed_2022_yolov11s_320.pt\")\n",
    "output_directory=os.path.join(working_directory,\"output_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice_pictures for training\n",
    "slicing(input_folder=pictures_directory,output_directory=working_directory,name_slicing=\"Slices_probando\", number_pictures=4, slice_height=320, slice_width=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label with CVAT\n",
    "\n",
    "zip_file_shell=os.path.join(working_directory,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model segmentation training\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file_shell, epochs=100,imgsz=640, name_segmentation=\"shell_2022_yolov11\",\n",
    "                                      pre_model=pre_model, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and reconstruct a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice_predict_reconstruct approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2025 17:34:49 - INFO - sahi.slicing -   image.shape: (756, 2934)\n",
      "01/17/2025 17:34:49 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detectada: NVIDIA GeForce RTX 3060\n",
      "Memoria total de la GPU: 12.00 GB\n",
      "Image1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2025 17:34:56 - INFO - sahi.slicing -   image.shape: (756, 2951)\n",
      "01/17/2025 17:34:56 - INFO - sahi.slicing -   Num slices: 36 slice_height: 320 slice_width: 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image2/2\n"
     ]
    }
   ],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=320, model_path=model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "\n",
    "for mask in masks:\n",
    "    cv2.imwrite(f\"{output_directory}/{os.path.basename(mask[1])}\", mask[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detectada: NVIDIA GeForce RTX 3060\n",
      "Memoria total de la GPU: 12.00 GB\n",
      "Pic 1/2\n",
      "Performing prediction on 36 slices.\n",
      "Pic 2/2\n",
      "Performing prediction on 36 slices.\n"
     ]
    }
   ],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "for mask in masks:\n",
    "    mask[0].export_visuals(export_dir=output_directory, hide_labels=True, rect_th=1, file_name=f\"{os.path.basename(mask[1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
