{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Develop your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation\n",
    "from aux_functions import slicing\n",
    "import cv2\n",
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "pictures_directory=os.path.join(working_directory, \"strawberry/strawberry_ejemplos\")\n",
    "pre_model=os.path.join(working_directory, \"models/yolo11s-seg.pt\")\n",
    "model_path=os.path.join(working_directory, \"models/strawberry.pt\")\n",
    "output_directory=os.path.join(working_directory,\"output_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice_pictures for training\n",
    "slicing(input_folder=pictures_directory,output_directory=working_directory,name_slicing=\"Slices_probando\", number_pictures=4, slice_height=320, slice_width=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label with CVAT\n",
    "\n",
    "zip_file_shell=os.path.join(working_directory,\"strawberry/strawberry_2025.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model segmentation training\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file_shell, epochs=50,imgsz=640, name_segmentation=\"strawberry\",\n",
    "                                      pre_model=pre_model, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and reconstruct a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice_predict_reconstruct approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:36:38 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:36:38 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Image 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:36:43 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:36:43 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:36:47 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:36:47 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:36:52 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:36:52 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:36:56 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:36:56 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:37:01 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:37:01 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:37:05 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:37:05 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:37:10 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:37:10 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:37:16 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:37:16 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 12:37:30 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/12/2025 12:37:30 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 10/10\n"
     ]
    }
   ],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=320, model_path=model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for mask in masks:\n",
    "    cv2.imwrite(f\"{output_directory}/{os.path.basename(mask[1])}\", mask[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Pic 1/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 2/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 3/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 4/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 5/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 6/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 7/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 8/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 9/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 10/10\n",
      "Performing prediction on 24 slices.\n"
     ]
    }
   ],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=640, slice_width=640,\n",
    "                                                  confidence_treshold=0.8,\n",
    "                                                  imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for mask in masks:\n",
    "    mask[0].export_visuals(export_dir=output_directory, hide_labels=True, rect_th=1, file_name=f\"{os.path.basename(mask[1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
