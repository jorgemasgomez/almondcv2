{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Develop your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation\n",
    "from aux_functions import slicing\n",
    "import cv2\n",
    "#Inputs\n",
    "working_directory=r\"C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\"\n",
    "pictures_directory=os.path.join(working_directory, \"pruebas\")\n",
    "pre_model=os.path.join(working_directory, \"models/yolo11s-seg.pt\")\n",
    "model_path=os.path.join(working_directory, \"last.pt\")\n",
    "output_directory=os.path.join(working_directory,\"output_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice_pictures for training\n",
    "slicing(input_folder=pictures_directory,output_directory=working_directory,name_slicing=\"Slices_apple\",\n",
    "         number_pictures=40, slice_height=640, slice_width=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label with CVAT\n",
    "\n",
    "zip_file_shell=os.path.join(working_directory,\"apple_640.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model segmentation training\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "model.train_segmentation_model(input_zip=zip_file_shell, epochs=100,imgsz=640, name_segmentation=\"apple\",\n",
    "                                      pre_model=pre_model, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and reconstruct a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice_predict_reconstruct approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:02 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 2/6\n",
      "Processing Image 3/6\n",
      "Processing Image 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:11:03 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 5/6\n",
      "Processing Image 6/6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=640, model_path=model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2, conf=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for mask in masks:\n",
    "    cv2.imwrite(f\"{output_directory}/{os.path.basename(mask[1])}\", mask[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=640, slice_width=640,\n",
    "                                                  confidence_treshold=0.8,\n",
    "                                                  imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the masks\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for mask in masks:\n",
    "    mask[0].export_visuals(export_dir=output_directory, hide_labels=True, rect_th=1, file_name=f\"{os.path.basename(mask[1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
