{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deploy your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation\n",
    "import pickle\n",
    "from pictures_class import Pictures\n",
    "import pandas as pd\n",
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "pictures_directory=os.path.join(working_directory, \"strawberry/strawberry_ejemplos\")\n",
    "model_path=os.path.join(working_directory, \"models/strawberry.pt\")\n",
    "info_data_completed_path=os.path.join(working_directory, \"prueba_info_strawberry.txt\")\n",
    "info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (almond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=320, model_path=model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando_watershed\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:12 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:12 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Image 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:18 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:18 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:22 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:22 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:27 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:27 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:32 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:32 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:37 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:37 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:42 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:42 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:46 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:46 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:51 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:51 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2025 09:13:55 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "02/13/2025 09:13:55 - INFO - sahi.slicing -   Num slices: 24 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 10/10\n"
     ]
    }
   ],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=640, model_path=model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:928: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  morphology_table = pd.concat([morphology_table, row], ignore_index=True)\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:942: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_table=pd.concat([general_table,row_general], ignore_index=True)\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:976: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_table['Binary_mask_picture'] = binary_table['Sample_picture'] + '_' + binary_table['Fruit_number'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando_watershed_strawberry\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Pic 1/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 2/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 3/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 4/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 5/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 6/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 7/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 8/10\n",
      "Performing prediction on 24 slices.\n",
      "Pic 9/10\n",
      "Performing prediction on 24 slices.\n"
     ]
    }
   ],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=640, slice_width=640,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"Strawberry_sahi\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
