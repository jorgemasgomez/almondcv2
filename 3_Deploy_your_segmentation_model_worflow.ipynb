{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deploy your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation, process_slice\n",
    "import pickle\n",
    "from pictures_class import Pictures\n",
    "import pandas as pd\n",
    "#Inputs\n",
    "working_directory=\"C:/Users/Pheno/Documents/database_almondcv2/\"\n",
    "pictures_directory=os.path.join(working_directory, \"strawberry/strawberry_ejemplos\")\n",
    "model_path=os.path.join(working_directory, \"models/strawberry.pt\")\n",
    "info_data_completed_path=os.path.join(working_directory, \"prueba_info_strawberry.txt\")\n",
    "info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (almond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/14/2025 16:51:04 - INFO - sahi.slicing -   image.shape: (3008, 1688)\n",
      "03/14/2025 16:51:04 - INFO - sahi.slicing -   Num slices: 84 slice_height: 320 slice_width: 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Processing Image 1/10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Join patches approach\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m=\u001b[39mModelSegmentation(working_directory\u001b[38;5;241m=\u001b[39mworking_directory)\n\u001b[1;32m----> 4\u001b[0m masks\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_predict_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpictures_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mslice_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moverlap_height_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43moverlap_width_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\model_class.py:382\u001b[0m, in \u001b[0;36mModelSegmentation.slice_predict_reconstruct\u001b[1;34m(self, imgsz, model_path, slice_width, slice_height, overlap_height_ratio, overlap_width_ratio, input_folder, conf, retina_mask, image_array)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# Crear y lanzar procesos\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m slice_data:\n\u001b[1;32m--> 382\u001b[0m     p \u001b[38;5;241m=\u001b[39m Process(target\u001b[38;5;241m=\u001b[39m\u001b[43mprocess_slice\u001b[49m, args\u001b[38;5;241m=\u001b[39m(queue, data))\n\u001b[0;32m    383\u001b[0m     p\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    384\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_slice' is not defined"
     ]
    }
   ],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=320, model_path=model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando_watershed\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=640, model_path=model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando_watershed_strawberry\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.05, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=640, slice_width=640,\n",
    "                                                  confidence_treshold=0.6,\n",
    "                                                  imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"Strawberry_sahi\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
