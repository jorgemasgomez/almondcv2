{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deploy your segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from model_class import ModelSegmentation\n",
    "import pickle\n",
    "from pictures_class import Pictures\n",
    "import pandas as pd\n",
    "#Inputs\n",
    "working_directory=r\"C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\"\n",
    "pictures_directory=os.path.join(working_directory, \"pruebas\")\n",
    "model_path=os.path.join(working_directory, \"last.pt\")\n",
    "info_data_completed_path=os.path.join(working_directory, \"prueba_info_apple.txt\")\n",
    "info_data_completed=pd.read_csv(info_data_completed_path,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (almond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=320, model_path=model_path,\n",
    "                                          slice_height=320, slice_width=320,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2, conf=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"apple\", binary_masks=True, project_name=\"rd\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.2, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=320, slice_width=320,\n",
    "                                                  confidence_treshold=0.95,\n",
    "                                                  imgsz=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"Shell_almond\", binary_masks=True, project_name=\"probando\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_almonds(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your reconstruction approach and measure (general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice predict reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_object.info_file[\"Pixelmetric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 2/6\n",
      "Processing Image 3/6\n",
      "Processing Image 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   image.shape: (1296, 1080)\n",
      "04/27/2025 11:19:32 - INFO - sahi.slicing -   Num slices: 6 slice_height: 640 slice_width: 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image 5/6\n",
      "Processing Image 6/6\n"
     ]
    }
   ],
   "source": [
    "# Join patches approach\n",
    "\n",
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.slice_predict_reconstruct(input_folder=pictures_directory,imgsz=640, model_path=model_path,\n",
    "                                          slice_height=640, slice_width=640,overlap_height_ratio=0.2,\n",
    "                                          overlap_width_ratio=0.2, conf=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641703_cam5_001_20201015_1156_06.jpg\n",
      "0110641703_cam5_001_20201015_1156_06.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam1_005_20200903_1414_37.jpg\n",
      "0110641805_cam1_005_20200903_1414_37.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:929: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  morphology_table = pd.concat([morphology_table, row], ignore_index=True)\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:943: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_table=pd.concat([general_table,row_general], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam2_001_20200903_1414_08.jpg\n",
      "0110641805_cam2_001_20200903_1414_08.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam2_004_20200903_1414_30.jpg\n",
      "0110641805_cam2_004_20200903_1414_30.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam4_001_20200903_1414_08.jpg\n",
      "0110641805_cam4_001_20200903_1414_08.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641807_cam3_004_20201015_1136_39.jpg\n",
      "0110641807_cam3_004_20201015_1136_39.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:977: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_table['Binary_mask_picture'] = binary_table['Sample_picture'] + '_' + binary_table['Fruit_number'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "## Example with slice predict reconstruct approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"apple\", binary_masks=True, project_name=\"apple\", blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=False, segmentation_input=masks, smoothing=False, smoothing_iterations=2, kernel_smoothing=3,\n",
    "                        watershed=True, kernel_watershed=5, threshold_watershed=0.6)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Save\n",
    "with open(f'{working_directory}/pictures_object_watershed.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU: NVIDIA GeForce RTX 3060\n",
      "Total GPU Memory: 12.00 GB\n",
      "Pic 1/6\n",
      "Performing prediction on 6 slices.\n",
      "Pic 2/6\n",
      "Performing prediction on 6 slices.\n",
      "Pic 3/6\n",
      "Performing prediction on 6 slices.\n",
      "Pic 4/6\n",
      "Performing prediction on 6 slices.\n",
      "Pic 5/6\n",
      "Performing prediction on 6 slices.\n",
      "Pic 6/6\n",
      "Performing prediction on 6 slices.\n"
     ]
    }
   ],
   "source": [
    "model=ModelSegmentation(working_directory=working_directory)\n",
    "masks=model.predict_model_sahi(model_path=model_path, check_result=False, folder_input=pictures_directory,\n",
    "                                            retina_masks=True,\n",
    "                                              postprocess_match_threshold=0.05, overlap_height_ratio=0.2,\n",
    "                                                overlap_width_ratio=0.2, postprocess_match_metric=\"IOS\", \n",
    "                                                postprocess_type=\"GREEDYNMM\", slice_height=640, slice_width=640,\n",
    "                                                  confidence_treshold=0.6,\n",
    "                                                  imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641703_cam5_001_20201015_1156_06.jpg\n",
      "0110641703_cam5_001_20201015_1156_06.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam1_005_20200903_1414_37.jpg\n",
      "0110641805_cam1_005_20200903_1414_37.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:929: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  morphology_table = pd.concat([morphology_table, row], ignore_index=True)\n",
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:943: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_table=pd.concat([general_table,row_general], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam2_001_20200903_1414_08.jpg\n",
      "0110641805_cam2_001_20200903_1414_08.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam2_004_20200903_1414_30.jpg\n",
      "0110641805_cam2_004_20200903_1414_30.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641805_cam4_001_20200903_1414_08.jpg\n",
      "0110641805_cam4_001_20200903_1414_08.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n",
      "C:\\Users\\Pheno\\Documents\\database_almondcv2\\apple_CV\\pruebas\\0110641807_cam3_004_20201015_1136_39.jpg\n",
      "0110641807_cam3_004_20201015_1136_39.jpg\n",
      "0    0110641703_cam5_001_20201015_1156_06.jpg\n",
      "1    0110641805_cam1_005_20200903_1414_37.jpg\n",
      "2    0110641805_cam2_001_20200903_1414_08.jpg\n",
      "3    0110641805_cam2_004_20200903_1414_30.jpg\n",
      "4    0110641805_cam4_001_20200903_1414_08.jpg\n",
      "5    0110641807_cam3_004_20201015_1136_39.jpg\n",
      "Name: Sample_picture, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pheno\\OneDrive - UNIVERSIDAD DE MURCIA\\Escritorio\\Almond_CV\\almondcv2\\pictures_class.py:977: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_table['Binary_mask_picture'] = binary_table['Sample_picture'] + '_' + binary_table['Fruit_number'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "## Example with SAHI approach\n",
    "pictures_object=Pictures(working_directory=working_directory, input_folder=pictures_directory,info_file=info_data_completed,\n",
    "                      fruit=\"apple_sahi\", binary_masks=True, project_name=\"apple_sahi\",  blurring_binary_masks=False)\n",
    "pictures_object.set_postsegmentation_parameters(sahi=True, segmentation_input=masks)\n",
    "pictures_object.measure_general(margin=400)\n",
    "\n",
    "# Guardar el objeto en un archivo\n",
    "with open(f'{working_directory}/pictures_object_sahi.pkl', 'wb') as file:\n",
    "    pickle.dump(pictures_object, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
